\babel@toc {english}{}
\contentsline {section}{\numberline {1}Introduction}{1}% 
\contentsline {subsection}{\numberline {1.1}Motivation}{1}% 
\contentsline {subsection}{\numberline {1.2}Objectives}{1}% 
\contentsline {section}{\numberline {2}Theoretical Background}{1}% 
\contentsline {subsection}{\numberline {2.1}Deep Reinforcement Learning}{1}% 
\contentsline {subsubsection}{\numberline {2.1.1}Target Networks}{3}% 
\contentsline {subsubsection}{\numberline {2.1.2}Experience Replay}{3}% 
\contentsline {subsection}{\numberline {2.2}Hierarchical Reinforcement Learning}{4}% 
\contentsline {subsubsection}{\numberline {2.2.1}Option-Critic}{5}% 
\contentsline {subsubsection}{\numberline {2.2.2}Feudal Networks}{6}% 
\contentsline {section}{\numberline {3}Specifications}{7}% 
\contentsline {subsection}{\numberline {3.1}System Requirements}{7}% 
\contentsline {section}{\numberline {4}System Design}{8}% 
\contentsline {subsection}{\numberline {4.1}Reward Function}{8}% 
\contentsline {subsection}{\numberline {4.2}Exploitation vs Exploration}{9}% 
\contentsline {subsection}{\numberline {4.3}Frame Preprocessing}{9}% 
\contentsline {subsection}{\numberline {4.4}Frame Stacking and Frame Skipping}{10}% 
\contentsline {subsection}{\numberline {4.5}Custom Levels}{10}% 
\contentsline {section}{\numberline {5}Experiments and Results}{10}% 
\contentsline {subsection}{\numberline {5.1}Experiment Design}{10}% 
\contentsline {subsection}{\numberline {5.2}DQN Agent}{10}% 
\contentsline {subsection}{\numberline {5.3}Option-Critic Agent}{10}% 
\contentsline {subsection}{\numberline {5.4}Feudal Agent}{10}% 
\contentsline {section}{References}{11}% 
