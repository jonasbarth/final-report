@ARTICLE{DRL_A_Brief_Survey,  author={K. {Arulkumaran} and M. P. {Deisenroth} and M. {Brundage} and A. A. {Bharath}},  journal={IEEE Signal Processing Magazine},  title={Deep Reinforcement Learning: A Brief Survey},   year={2017},  volume={34},  number={6},  pages={26-38},}

@article{DBLP:journals/corr/MnihKSGAWR13,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  archivePrefix = {arXiv},
  eprint    = {1312.5602},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MnihKSGAWR13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{alpha_go,
title	= {Mastering the game of Go with deep neural networks and tree search},
author	= {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
year	= {2016},
URL	= {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
journal	= {Nature},
pages	= {484--503},
volume	= {529}
}


@inproceedings{arulkumaran2019alphastar,
  title={Alphastar: An evolutionary computation perspective},
  author={Arulkumaran, Kai and Cully, Antoine and Togelius, Julian},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  pages={314--315},
  year={2019}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}

@article{nachum2019does,
  title={Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?},
  author={Nachum, Ofir and Tang, Haoran and Lu, Xingyu and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1909.10618},
  year={2019}
}

@book{siebert2001kobra,
  title={Der Kobra-Effekt: Wie man Irrwege der Wirtschaftspolitik vermeidet},
  author={Siebert, Horst},
  year={2001},
  publisher={Dt. Verlag-Anst.}
}

@misc{marioai,
	title={Mario AI Framework 10th Anniversary Edition},
	author={Ahmed Khalifa},
	year={2019},
	url={https://github.com/amidos2006/Mario-AI-Framework}
}


@misc{jython,
	title={Jython},
	url={https://www.jython.org/}
}

@misc{jpype,
	title={JPype},
	url={https://jpype.readthedocs.io/en/latest/}
}

@misc{py4j,
	title={Py4J},
	url={https://www.py4j.org/}
}

@article{chuchro2017game,
  title={Game playing with deep q-learning using openai gym},
  author={Chuchro, Robert and Gupta, Deepak},
  journal={Semantic Scholar},
  year={2017}
}

@article{sutton2011reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2011},
  publisher={Cambridge, MA: MIT Press}
}


@book{white2012bandit,
  title={Bandit algorithms for website optimization},
  author={White, John},
  year={2012},
  publisher={" O'Reilly Media, Inc."}
}


@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}


@article{maroti2019rbed,
  title={RBED: Reward Based Epsilon Decay},
  author={Maroti, Aakash},
  journal={arXiv preprint arXiv:1910.13701},
  year={2019}
}


@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}


@article{franccois2018introduction,
  title={An introduction to deep reinforcement learning},
  author={Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={3-4},
  pages={219--354},
  year={2018},
  publisher={Now Publishers, Inc.}
}


@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{geirhos2018generalisation,
  title={Generalisation in humans and deep neural networks},
  author={Geirhos, Robert and Temme, Carlos RM and Rauber, Jonas and Sch{\"u}tt, Heiko H and Bethge, Matthias and Wichmann, Felix A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7538--7550},
  year={2018}
}

@inproceedings{sutton1996generalization,
  title={Generalization in reinforcement learning: Successful examples using sparse coarse coding},
  author={Sutton, Richard S},
  booktitle={Advances in neural information processing systems},
  pages={1038--1044},
  year={1996}
}


@inproceedings{van2017hybrid,
  title={Hybrid reward architecture for reinforcement learning},
  author={Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5392--5402},
  year={2017}
}

@article{cobbe2018quantifying,
  title={Quantifying generalization in reinforcement learning},
  author={Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
  journal={arXiv preprint arXiv:1812.02341},
  year={2018}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{ribas2011neural,
  title={A neural signature of hierarchical reinforcement learning},
  author={Ribas-Fernandes, Jose JF and Solway, Alec and Diuk, Carlos and McGuire, Joseph T and Barto, Andrew G and Niv, Yael and Botvinick, Matthew M},
  journal={Neuron},
  volume={71},
  number={2},
  pages={370--379},
  year={2011},
  publisher={Elsevier}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{bacon2017option,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}


@techreport{lin1993reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long-Ji},
  year={1993},
  institution={Carnegie-Mellon Univ Pittsburgh PA School of Computer Science}
}